{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "import evaluate\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import datasets\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "from rdkit import Chem\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import math\n",
    "\n",
    "import itertools\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import os\n",
    "\n",
    "# os.environ[\"WANDB_API_KEY\"] = \"<API_KEY>\" # Optional: Add your Weights & Biases API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def control_smiles_duplication(random_smiles, duplicate_control=lambda x: 1):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Returns augmented SMILES with the number of duplicates controlled by the function duplicate_control.\n",
    "\n",
    "\n",
    "\n",
    "    Taken from https://github.com/volkamerlab/maxsmi/blob/main/maxsmi/utils/utils_smiles.py\n",
    "\n",
    "\n",
    "\n",
    "    Parameters\n",
    "\n",
    "    ----------\n",
    "\n",
    "    random_smiles : list\n",
    "\n",
    "        A list of random SMILES, can be obtained by `smiles_to_random()`.\n",
    "\n",
    "    duplicate_control : func, Optional, default: 1\n",
    "\n",
    "        The number of times a SMILES will be duplicated, as function of the number of times\n",
    "\n",
    "        it was included in `random_smiles`.\n",
    "\n",
    "        This number is rounded up to the nearest integer.\n",
    "\n",
    "\n",
    "\n",
    "    Returns\n",
    "\n",
    "    -------\n",
    "\n",
    "    list\n",
    "\n",
    "        A list of random SMILES with duplicates.\n",
    "\n",
    "\n",
    "\n",
    "    Notes\n",
    "\n",
    "    -----\n",
    "\n",
    "    When `duplicate_control=lambda x: 1`, then the returned list contains only unique SMILES.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    counted_smiles = Counter(random_smiles)\n",
    "\n",
    "    smiles_duplication = {\n",
    "\n",
    "        smiles: math.ceil(duplicate_control(counted_smiles[smiles]))\n",
    "\n",
    "        for smiles in counted_smiles\n",
    "\n",
    "    }\n",
    "\n",
    "    return list(\n",
    "\n",
    "        itertools.chain.from_iterable(\n",
    "\n",
    "            [[smiles] * smiles_duplication[smiles] for smiles in smiles_duplication]\n",
    "\n",
    "        )\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def smiles_to_random(smiles, int_aug=50):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Takes a SMILES (not necessarily canonical) and returns `int_aug` random variations of this SMILES.\n",
    "\n",
    "\n",
    "\n",
    "    Taken from https://github.com/volkamerlab/maxsmi/blob/main/maxsmi/utils/utils_smiles.py\n",
    "\n",
    "\n",
    "\n",
    "    Parameters\n",
    "\n",
    "    ----------\n",
    "\n",
    "    smiles : str\n",
    "\n",
    "        SMILES string describing a compound.\n",
    "\n",
    "    int_aug : int, Optional, default: 50\n",
    "\n",
    "        The number of random SMILES generated.\n",
    "\n",
    "\n",
    "\n",
    "    Returns\n",
    "\n",
    "    -------\n",
    "\n",
    "    list\n",
    "\n",
    "        A list of `int_aug` random (may not be unique) SMILES or None if the initial SMILES is not valid.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "\n",
    "\n",
    "    if mol is None:\n",
    "\n",
    "        return None\n",
    "\n",
    "    else:\n",
    "\n",
    "        if int_aug > 0:\n",
    "\n",
    "            return [\n",
    "\n",
    "                Chem.MolToSmiles(mol, canonical=False, doRandom=True)\n",
    "\n",
    "                for _ in range(int_aug)\n",
    "\n",
    "            ]\n",
    "\n",
    "        elif int_aug == 0:\n",
    "\n",
    "            return [smiles]\n",
    "\n",
    "        else:\n",
    "\n",
    "            raise ValueError(\"int_aug must be greater or equal to zero.\")\n",
    "\n",
    "\n",
    "\n",
    "def augmentation_without_duplication(smiles, augmentation_number):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Takes a SMILES and returns a list of unique random SMILES.\n",
    "\n",
    "\n",
    "\n",
    "    Taken from https://github.com/volkamerlab/maxsmi/blob/main/maxsmi/utils/utils_smiles.py\n",
    "\n",
    "\n",
    "\n",
    "    Parameters\n",
    "\n",
    "    ----------\n",
    "\n",
    "    smiles : str\n",
    "\n",
    "        SMILES string describing a compound.\n",
    "\n",
    "    augmentation_number : int\n",
    "\n",
    "        The integer to generate the number of random SMILES.\n",
    "\n",
    "\n",
    "\n",
    "    Returns\n",
    "\n",
    "    -------\n",
    "\n",
    "    list\n",
    "\n",
    "        A list of unique random SMILES (no duplicates).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    smiles_list = smiles_to_random(smiles, augmentation_number)\n",
    "\n",
    "    return control_smiles_duplication(smiles_list, lambda x: 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df = pd.read_csv(\"fart_train.csv\")\n",
    "val_df = pd.read_csv(\"fart_val.csv\")\n",
    "test_df = pd.read_csv(\"fart_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index to avoid \"__index_level_0__\" column\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "val_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "augmentation = False # Set to True to augment the dataset\n",
    "\n",
    "if augmentation:\n",
    "\n",
    "    # Function to augment dataset based on umami taste\n",
    "\n",
    "    \n",
    "\n",
    "    def augment_dataset(dataset, augmentation_numbers,tastes):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Augments the dataset by generating new SMILES strings for specified tastes.\n",
    "\n",
    "\n",
    "\n",
    "        Args:\n",
    "\n",
    "            dataset (Dataset): The original dataset.\n",
    "\n",
    "            augmentation_numbers (list): Numbers of new SMILES to generate for each taste.\n",
    "\n",
    "            tastes (list): Taste categories to augment.\n",
    "\n",
    "\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            Dataset: Augmented dataset with new SMILES strings.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        augmented_data = []\n",
    "\n",
    "        for i, taste in enumerate(tastes):\n",
    "\n",
    "            for entry in dataset:\n",
    "\n",
    "                if entry[\"Canonicalized Taste\"] == taste:\n",
    "\n",
    "                    original_smiles = entry[\"Canonicalized SMILES\"]\n",
    "                    new_smiles_list = augmentation_without_duplication(original_smiles, augmentation_numbers[i])\n",
    "\n",
    "\n",
    "\n",
    "                    for new_smiles in new_smiles_list:\n",
    "\n",
    "                        new_entry = deepcopy(entry)\n",
    "\n",
    "                        new_entry[\"Canonicalized SMILES\"] = new_smiles\n",
    "\n",
    "                        augmented_data.append(new_entry)\n",
    "\n",
    "                else:\n",
    "\n",
    "                    augmented_data.append(entry)\n",
    "\n",
    "\n",
    "\n",
    "        # Convert augmented_data list to Dataset object\n",
    "\n",
    "        augmented_dataset = Dataset.from_dict({key: [entry[key] for entry in augmented_data] for key in augmented_data[0]})\n",
    "\n",
    "\n",
    "\n",
    "        return augmented_dataset\n",
    "\n",
    "\n",
    "\n",
    "    tastes = ['bitter', 'sour', 'sweet', 'umami', 'undefined']\n",
    "\n",
    "    augmentation_numbers = [10, 10, 10, 10, 10] # Number of new SMILES to generate for each taste\n",
    "\n",
    "\n",
    "\n",
    "    train_dataset = augment_dataset(train_dataset, augmentation_numbers, tastes)\n",
    "\n",
    "\n",
    "\n",
    "    val_dataset = augment_dataset(val_dataset, augmentation_numbers, tastes)\n",
    "\n",
    "\n",
    "\n",
    "    test_dataset = augment_dataset(test_dataset, augmentation_numbers, tastes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "\n",
    "model_checkpoint = \"seyonec/SMILES_tokenized_PubChem_shard00_160k\"  # Edit this line to use a different pretrained model\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "\n",
    "    return tokenizer(examples[\"Canonicalized SMILES\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "\n",
    "encoded_labels = label_encoder.fit_transform(train_dataset['Canonicalized Taste'])\n",
    "\n",
    "train_dataset = train_dataset.add_column('label', encoded_labels)\n",
    "\n",
    "encoded_labels = label_encoder.fit_transform(val_dataset['Canonicalized Taste'])\n",
    "\n",
    "val_dataset = val_dataset.add_column('label', encoded_labels)\n",
    "\n",
    "encoded_labels = label_encoder.fit_transform(test_dataset['Canonicalized Taste'])\n",
    "\n",
    "test_dataset = test_dataset.add_column('label', encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Computes accuracy metrics for evaluation predictions.\n",
    "\n",
    "\n",
    "\n",
    "    Args:\n",
    "\n",
    "        eval_pred (tuple): A tuple containing logits and labels.\n",
    "\n",
    "\n",
    "\n",
    "    Returns:\n",
    "\n",
    "        dict: A dictionary with the accuracy metric.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    logits, labels = eval_pred\n",
    "\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder.inverse_transform(range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 5\n",
    "model_checkpoint = \"seyonec/SMILES_tokenized_PubChem_shard00_160k\" # Edit this line to use a different pretrained model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "\n",
    "    run_name = \"<RUN_NAME>\", # Optional: Add a name for the run to identify it in Weights & Biases\n",
    "\n",
    "    output_dir=\"./results\",\n",
    "\n",
    "    num_train_epochs=2,\n",
    "\n",
    "    per_device_train_batch_size=16,\n",
    "\n",
    "    per_device_eval_batch_size=16,\n",
    "\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    evaluation_strategy=\"steps\",\n",
    "\n",
    "    logging_dir=\"./logs\",\n",
    "\n",
    "    save_strategy=\"steps\",\n",
    "\n",
    "    load_best_model_at_end=True,\n",
    "\n",
    "    save_total_limit=5,\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the Trainer\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "\n",
    "    model=model,\n",
    "\n",
    "    args=training_args,\n",
    "\n",
    "    train_dataset=train_dataset,\n",
    "\n",
    "    eval_dataset=val_dataset,\n",
    "    \n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train() # Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate(eval_dataset=val_dataset)    # Evaluate the model after training with best eval score\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(test_dataset)             # Predict on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = softmax(predictions.predictions, axis=1)\n",
    "pred_labels = np.argmax(probs, axis=1)\n",
    "true_labels = predictions.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(true_labels, pred_labels)\n",
    "\n",
    "label_names = label_encoder.inverse_transform(range(5))\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap='Blues', xticklabels=label_names, yticklabels=label_names)\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plt.ylabel('Actual Label')\n",
    "\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "\n",
    "accuracy = accuracy_score(true_labels, pred_labels)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Calculate precision, recall, and F1 score for each class\n",
    "\n",
    "precision, recall, f1, support = precision_recall_fscore_support(true_labels, pred_labels)\n",
    "\n",
    "\n",
    "\n",
    "# Optionally, if you want to calculate the weighted scores as well\n",
    "\n",
    "precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(true_labels, pred_labels, average='macro')\n",
    "\n",
    "print(f\"Weighted Precision: {precision_weighted:.4f}\")\n",
    "\n",
    "print(f\"Weighted Recall: {recall_weighted:.4f}\")\n",
    "\n",
    "print(f\"Weighted F1 Score: {f1_weighted:.4f}\")\n",
    "\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "for i, (p, r, f, s) in enumerate(zip(precision, recall, f1, support)):\n",
    "\n",
    "    print(f\"Class {class_names[i]}:\")\n",
    "\n",
    "    print(f\"  Precision: {p:.4f}\")\n",
    "\n",
    "    print(f\"  Recall: {r:.4f}\")\n",
    "\n",
    "    print(f\"  F1 Score: {f:.4f}\")\n",
    "\n",
    "    print(f\"  Support: {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves for each class\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "num_classes = probs.shape[1]\n",
    "\n",
    "# Binarize the true labels\n",
    "true_labels_bin = label_binarize(true_labels, classes=np.arange(num_classes))\n",
    "\n",
    "class_labels = label_encoder.inverse_transform(range(5))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "auc_scores = []\n",
    "for i in range(num_classes):\n",
    "    if np.sum(true_labels_bin[:, i]) > 0:  # Check if the class is in y_true\n",
    "        auc = roc_auc_score(true_labels_bin[:, i], probs[:, i])\n",
    "        auc_scores.append(auc)\n",
    "        fpr, tpr, _ = roc_curve(true_labels_bin[:, i], probs[:, i])\n",
    "        plt.plot(fpr, tpr, label=f\"{class_labels[i]} (AUC = {auc:.4f})\")\n",
    "    else:\n",
    "        print(f\"{class_labels[i]} not present in true_labels.\")\n",
    "\n",
    "# Plot the random classifier line\n",
    "plt.plot([0, 1], [0, 1], 'k--', label=\"Random Classifier (AUC = 0.5)\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curves for Each Class\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('ROC.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble voting (Confidence)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Standardized SMILES': test_dataset['Standardized SMILES'],\n",
    "    'label': test_dataset['label'],\n",
    "    'pred_probs': list(softmax(predictions.predictions, axis=1))\n",
    "})\n",
    "\n",
    "df['pred_labels'] = np.argmax(df['pred_probs'].tolist(), axis=1)\n",
    "\n",
    "# Majority voting for each molecule (Parent_SMILES group)\n",
    "grouped = df.groupby('Standardized SMILES').agg({\n",
    "    'pred_labels': lambda x: x.value_counts().idxmax() if x.value_counts().iloc[0] >= 10 else np.nan,\n",
    "    'label': 'first' \n",
    "}).dropna().reset_index()\n",
    "\n",
    "num_classes = predictions.predictions.shape[1]\n",
    "true_labels_bin = label_binarize(grouped['label'], classes=np.arange(num_classes))\n",
    "pred_probs = np.array([np.mean(df.loc[df['Standardized SMILES'] == smile, 'pred_probs'], axis=0) \n",
    "                       for smile in grouped['Standardized SMILES']])\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "auc_scores = []\n",
    "for i in range(num_classes):\n",
    "    if np.sum(true_labels_bin[:, i]) > 0:  # Check if class is present in true labels\n",
    "        auc = roc_auc_score(true_labels_bin[:, i], pred_probs[:, i])\n",
    "        auc_scores.append(auc)\n",
    "        fpr, tpr, _ = roc_curve(true_labels_bin[:, i], pred_probs[:, i])\n",
    "        plt.plot(fpr, tpr, label=f\"{class_labels[i]} (AUC = {auc:.4f})\")\n",
    "    else:\n",
    "        print(f\"{class_labels[i]} not present in true labels.\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label=\"Random Classifier (AUC = 0.5)\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curves for Each Class (Ensemble Voting)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('ROC_voted.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Filtered true and predicted labels from the ensemble voting process\n",
    "true_labels_voted = grouped['label'].values\n",
    "pred_labels_voted = grouped['pred_labels'].values\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels_voted, pred_labels_voted)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Calculate precision, recall, and F1 score for each class\n",
    "precision, recall, f1, support = precision_recall_fscore_support(true_labels_voted, pred_labels_voted, labels=np.arange(num_classes))\n",
    "\n",
    "# Optionally, calculate the weighted scores as well\n",
    "precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
    "    true_labels_voted, pred_labels_voted, average='macro', labels=np.arange(num_classes))\n",
    "print(f\"Weighted Precision: {precision_weighted:.4f}\")\n",
    "print(f\"Weighted Recall: {recall_weighted:.4f}\")\n",
    "print(f\"Weighted F1 Score: {f1_weighted:.4f}\")\n",
    "\n",
    "# Print scores for each class\n",
    "for i, (p, r, f, s) in enumerate(zip(precision, recall, f1, support)):\n",
    "    print(f\"Class {class_labels[i]}:\")\n",
    "    print(f\"  Precision: {p:.4f}\")\n",
    "    print(f\"  Recall: {r:.4f}\")\n",
    "    print(f\"  F1 Score: {f:.4f}\")\n",
    "    print(f\"  Support: {s}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Comparison to Binary Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Confidence = True # Set to True to use confidence-based ensemble voting\n",
    "\n",
    "if Confidence:\n",
    "    assert augmented == True # Confidence-based ensemble voting requires augmented dataset\n",
    "    df = pd.DataFrame({\n",
    "        'Standardized SMILES': test_dataset['Standardized SMILES'],\n",
    "        'label': test_dataset['label'],\n",
    "        'pred_probs': list(softmax(predictions.predictions, axis=1))\n",
    "    })\n",
    "    \n",
    "    # Get the predicted labels\n",
    "    df['pred_labels'] = np.argmax(df['pred_probs'].tolist(), axis=1)\n",
    "    \n",
    "    grouped = df.groupby('Standardized SMILES').agg({\n",
    "        'pred_labels': lambda x: x.value_counts().idxmax() if x.value_counts().iloc[0] >= 10 else np.nan,\n",
    "        'label': 'first',  # Assume all SMILES for a molecule have the same true label\n",
    "        'pred_probs': lambda x: np.mean(np.vstack(x), axis=0)  # Aggregate probabilities\n",
    "    }).dropna().reset_index()\n",
    "    \n",
    "    grouped['final_pred_label'] = grouped['pred_probs'].apply(lambda x: np.argmax(x))\n",
    "    \n",
    "    probs = grouped[\"pred_probs\"].tolist()\n",
    "    pred_labels = grouped[\"pred_labels\"].tolist()\n",
    "    true_labels = grouped[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_class = \"bitter\" # Edit this line to use a different class\n",
    "positive_class = label_encoder.transform([positive_class])[0]\n",
    "\n",
    "# Binarize the labels\n",
    "true_binary = [1 if label == positive_class else 0 for label in true_labels]\n",
    "pred_binary = [1 if label == positive_class else 0 for label in pred_labels]\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(true_binary, pred_binary)\n",
    "report = classification_report(true_binary, pred_binary, target_names=['non-' + positive_class, positive_class], output_dict=True)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "positive_class = \"bitter\" # Edit this line to use a different class\n",
    "index = label_encoder.transform([positive_class])[0]\n",
    "\n",
    "# Extract sweet probabilities\n",
    "probs = [prob[index] for prob in probs]\n",
    "\n",
    "# Binarize the true labels\n",
    "positive_class = index\n",
    "true_binary = [1 if label == positive_class else 0 for label in true_labels]\n",
    "\n",
    "# Compute AUROC\n",
    "auroc = roc_auc_score(true_binary, probs)\n",
    "\n",
    "# Output the result\n",
    "print(f\"Binarized AUROC for {positive_class}/non-{positive_class} classification: {auroc}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4638450,
     "sourceId": 7898547,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4942668,
     "sourceId": 8322900,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5048114,
     "sourceId": 8467007,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5293783,
     "sourceId": 8802631,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6003691,
     "sourceId": 9796557,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6228369,
     "sourceId": 10098762,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
