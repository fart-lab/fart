{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Baselines for FART "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, rdFingerprintGenerator\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    precision_recall_fscore_support,\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16:50:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:50:29] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:50:29] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:50:29] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:50:29] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "# Loading the curated dataset from a CSV file\n",
    "data = pd.read_csv('fart_curated.csv')\n",
    "\n",
    "# Define a function to convert SMILES to fingerprints\n",
    "def smiles_to_fingerprints(smiles, n_bits=1024):\n",
    "    \"\"\"\n",
    "    Converts a SMILES string to a molecular fingerprint.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    smiles : str\n",
    "        A SMILES string representing the molecular structure.\n",
    "    n_bits : int, Optional, default: 1024\n",
    "        The number of bits in the fingerprint.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of integers representing the molecular fingerprint.\n",
    "        Returns a zero vector if the SMILES string is invalid.\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is not None:\n",
    "        mfpgen = rdFingerprintGenerator.GetMorganGenerator(radius=2,fpSize=2048)\n",
    "        return mfpgen.GetFingerprint(mol).ToList()\n",
    "    else:\n",
    "        return [0] * n_bits  # Return a zero vector if the SMILES is invalid\n",
    "\n",
    "# Get Morgan fingerprints from SMILES\n",
    "data['fingerprints'] = data['Standardized SMILES'].apply(smiles_to_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "\n",
    "def return_scores(all_y_pred, all_y_true, y, title=\"Define Title\"):\n",
    "\n",
    "    # Get unique classes\n",
    "    classes = np.unique(all_y_true)\n",
    "\n",
    "    # Binarize the true and predicted labels for multi-class AUC calculation\n",
    "    y_true_bin = label_binarize(all_y_true, classes=classes)\n",
    "    y_pred_bin = label_binarize(all_y_pred, classes=classes)\n",
    "\n",
    "    # Calculate AUC for each class using One-vs-Rest (OvR) method\n",
    "  \n",
    "    # Average AUC across all classes\n",
    "    avg_auc = roc_auc_score(y_true_bin, y_pred_bin, average=\"macro\", multi_class=\"ovr\")\n",
    "\n",
    "    # Weighted AUC, which considers the support of each class\n",
    "    weighted_auc = roc_auc_score(y_true_bin, y_pred_bin, average=\"weighted\", multi_class=\"ovr\")\n",
    "\n",
    "\n",
    "    print(f\"{title}\")\n",
    "    # Calculate overall accuracy\n",
    "    overall_accuracy = accuracy_score(all_y_true, all_y_pred)\n",
    "\n",
    "    # Print classification report for per-class metrics\n",
    "    print(\"\\nPer-Class Classification Report:\")\n",
    "    print(classification_report(all_y_true, all_y_pred, target_names=np.unique(y), digits=4))\n",
    "\n",
    "    # Calculate weighted and macro averages for precision, recall, and F1 score\n",
    "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
    "        all_y_true, all_y_pred, average='weighted'\n",
    "    )\n",
    "\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "        all_y_true, all_y_pred, average='macro'\n",
    "    )\n",
    "\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "\n",
    "    # Print weighted averages\n",
    "    print(\"\\nWeighted Averages:\")\n",
    "    print(f\"Weighted Precision: {precision_weighted:.4f}\")\n",
    "    print(f\"Weighted Recall: {recall_weighted:.4f}\")\n",
    "    print(f\"Weighted F1 Score: {f1_weighted:.4f}\")\n",
    "    print(f\"Weighted Average AUC: {weighted_auc:.4f}\")\n",
    "\n",
    "    # Print unweighted (macro) averages\n",
    "    print(\"\\nMacro Averages (Unweighted):\")\n",
    "    print(f\"Macro Precision: {precision_macro:.4f}\")\n",
    "    print(f\"Macro Recall: {recall_macro:.4f}\")\n",
    "    print(f\"Macro F1 Score: {f1_macro:.4f}\")\n",
    "    print(f\"Average AUC (macro): {avg_auc:.4f}\")\n",
    "\n",
    "    # Optional: Calculate per-class precision, recall, and F1 score explicitly\n",
    "    # Get per-class metrics using precision_recall_fscore_support without averaging\n",
    "    precision_per_class, recall_per_class, f1_per_class, _ = precision_recall_fscore_support(\n",
    "        all_y_true, all_y_pred, average=None, labels=np.unique(all_y_true)\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost on fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Convert features list to a numpy array for modeling\n",
    "X1 = np.array(data['fingerprints'].tolist())\n",
    "y1 = data['Canonicalized Taste'].values\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder and transform the labels to integers\n",
    "y1_encoded = encoder.fit_transform(y1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py310_env/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [14:35:49] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py310_env/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [14:35:56] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py310_env/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [14:36:02] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py310_env/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [14:36:09] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py310_env/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [14:36:16] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Define the XGBClassifier model, same parameters as for the other RF models\n",
    "model = XGBClassifier(\n",
    "    n_estimators=150,\n",
    "    max_depth=15,\n",
    "    learning_rate=0.01,\n",
    "    subsample=0.8,               # now with full subsampling rate\n",
    "    objective='multi:softprob',\n",
    "    num_class=5,\n",
    "    eval_metric='mlogloss',\n",
    "    device='gpu',  # Ensure GPU is used for tree construction\n",
    "    random_state=101\n",
    ")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=101, shuffle=True)\n",
    "\n",
    "# Lists to store predictions and true labels across all folds\n",
    "all_y1_pred = []\n",
    "all_y1_true = []\n",
    "\n",
    "# Perform K-fold cross-validation\n",
    "for train_index, val_index in skf.split(X1, y1_encoded):\n",
    "    X1_train, X1_val = X1[train_index], X1[val_index]\n",
    "    y1_train, y1_val = y1_encoded[train_index], y1_encoded[val_index]\n",
    "\n",
    "    # Fit the model on training data\n",
    "    model.fit(X1_train, y1_train)\n",
    "\n",
    "    # Predict probabilities for the test set\n",
    "    y1_pred_proba = model.predict_proba(X1_val)\n",
    "\n",
    "    # Predicted class: highest probability\n",
    "    y1_pred = np.argmax(y1_pred_proba, axis=1)\n",
    "\n",
    "    # Collect true labels and predictions for evaluation\n",
    "    all_y1_true.extend(y1_val)\n",
    "    all_y1_pred.extend(y1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost on Fingerprints\n",
      "\n",
      "Per-Class Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      bitter     0.8104    0.5943    0.6857      1676\n",
      "        sour     0.8242    0.8941    0.8577      1605\n",
      "       sweet     0.9288    0.9257    0.9273      9542\n",
      "       umami     0.7600    0.3276    0.4578        58\n",
      "   undefined     0.6338    0.7447    0.6848      2150\n",
      "\n",
      "    accuracy                         0.8572     15031\n",
      "   macro avg     0.7915    0.6973    0.7227     15031\n",
      "weighted avg     0.8616    0.8572    0.8564     15031\n",
      "\n",
      "Overall Accuracy: 0.8572\n",
      "\n",
      "Weighted Averages:\n",
      "Weighted Precision: 0.8616\n",
      "Weighted Recall: 0.8572\n",
      "Weighted F1 Score: 0.8564\n",
      "Weighted Average AUC: 0.8821\n",
      "\n",
      "Macro Averages (Unweighted):\n",
      "Macro Precision: 0.7915\n",
      "Macro Recall: 0.6973\n",
      "Macro F1 Score: 0.7227\n",
      "Average AUC (macro): 0.8250\n"
     ]
    }
   ],
   "source": [
    "return_scores(all_y1_pred, all_y1_true, y1, title=\"XGBoost on Fingerprints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost on fingerprints and 15 Mordred Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[14:32:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:32:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:32:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:32:33] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:32:33] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:32:33] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:32:40] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:32:40] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:32:40] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:32:40] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:32:40] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:32:40] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:32:41] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:32:41] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:32:41] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "from mordred import Calculator, descriptors # requires python version 3.10 or earlier\n",
    "\n",
    "\n",
    "# Create a Mordred Calculator\n",
    "calc = Calculator()\n",
    "\n",
    "# Add specific descriptors to the calculator: https://mordred-descriptor.github.io/documentation/master/descriptors.html\n",
    "calc.register(descriptors.Autocorrelation.ATSC(0, 'c'))\n",
    "calc.register(descriptors.Autocorrelation.ATSC(0, 'se'))\n",
    "calc.register(descriptors.Autocorrelation.AATS(0, 'i'))\n",
    "calc.register(descriptors.Autocorrelation.ATSC(1, 'p'))\n",
    "calc.register(descriptors.Autocorrelation.AATSC(2, 'se'))\n",
    "calc.register(descriptors.Autocorrelation.AATSC(0, 'm'))\n",
    "calc.register(descriptors.Autocorrelation.AATSC(1, 'Z'))\n",
    "calc.register(descriptors.Autocorrelation.AATSC(2, 'are'))\n",
    "calc.register(descriptors.Autocorrelation.AATSC(1, 'pe'))\n",
    "calc.register(descriptors.AdjacencyMatrix.AdjacencyMatrix('SpDiam'))\n",
    "calc.register(descriptors.Autocorrelation.ATSC(1, 'c'))\n",
    "calc.register(descriptors.Autocorrelation.ATSC(1, 'se'))\n",
    "calc.register(descriptors.Autocorrelation.ATSC(1, 'Z'))\n",
    "calc.register(descriptors.Autocorrelation.ATSC(1, 'm'))\n",
    "calc.register(descriptors.Autocorrelation.ATSC(4, 's'))\n",
    "\n",
    "\n",
    "def generate_descriptors(smiles, calculator=calc):\n",
    "    \"\"\"\n",
    "    Calculates selected descriptors from SMILES\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    smiles : str\n",
    "        A SMILES string representing the molecular structure.\n",
    "    calculator : Calculator\n",
    "        A mordred Calculator with given descriptors.\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    if calculator is None:\n",
    "        return None\n",
    "\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "    try:\n",
    "      return calculator(mol)\n",
    "\n",
    "    except Exception as error:\n",
    "      return None\n",
    "\n",
    "data['mordred_descriptors'] = data['Standardized SMILES'].apply(generate_descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Convert features list to a numpy array for modeling\n",
    "X_fingerprints = np.array(data['fingerprints'].tolist())\n",
    "X_descriptors = np.array(data['mordred_descriptors'].tolist())\n",
    "\n",
    "X2 = np.concatenate((X_fingerprints, X_descriptors), axis=1)\n",
    "y2 = data['Canonicalized Taste'].values\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder and transform the labels to integers\n",
    "y2_encoded = encoder.fit_transform(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py310_env/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [14:33:11] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py310_env/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [14:33:20] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py310_env/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [14:33:30] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py310_env/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [14:33:41] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py310_env/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [14:33:51] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define the XGBClassifier model, same parameters as for the other RF models\n",
    "model_descriptors = XGBClassifier(\n",
    "    n_estimators=150,\n",
    "    max_depth=15,\n",
    "    learning_rate=0.01,\n",
    "    subsample=0.8,               # now with full subsampling rate\n",
    "    objective='multi:softprob',\n",
    "    num_class=5,\n",
    "    eval_metric='mlogloss',\n",
    "    device='gpu',  # Ensure GPU is used for tree construction\n",
    "    random_state=101\n",
    ")\n",
    "skf = StratifiedKFold(n_splits=5, random_state=101, shuffle=True)\n",
    "\n",
    "# Lists to store predictions and true labels across all folds\n",
    "all_y2_pred = []\n",
    "all_y2_true = []\n",
    "\n",
    "# Perform K-fold cross-validation\n",
    "for train_index, val_index in skf.split(X2, y2_encoded):\n",
    "    X2_train, X2_val = X2[train_index], X2[val_index]\n",
    "    y2_train, y2_val = y2_encoded[train_index], y2_encoded[val_index]\n",
    "\n",
    "    # Fit the model on training data\n",
    "    model_descriptors.fit(X2_train, y2_train)\n",
    "\n",
    "    # Predict probabilities for the test set\n",
    "    y2_pred_proba = model_descriptors.predict_proba(X2_val)\n",
    "\n",
    "    # Predicted class: highest probability\n",
    "    y2_pred = np.argmax(y2_pred_proba, axis=1)\n",
    "\n",
    "    # Collect true labels and predictions for evaluation\n",
    "    all_y2_true.extend(y2_val)\n",
    "    all_y2_pred.extend(y2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost on fp+descriptors\n",
      "\n",
      "Per-Class Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      bitter     0.7842    0.6116    0.6872      1676\n",
      "        sour     0.8292    0.8773    0.8526      1605\n",
      "       sweet     0.9146    0.9299    0.9222      9542\n",
      "       umami     0.7273    0.2759    0.4000        58\n",
      "   undefined     0.6490    0.6949    0.6712      2150\n",
      "\n",
      "    accuracy                         0.8526     15031\n",
      "   macro avg     0.7809    0.6779    0.7066     15031\n",
      "weighted avg     0.8522    0.8526    0.8506     15031\n",
      "\n",
      "Overall Accuracy: 0.8526\n",
      "\n",
      "Weighted Averages:\n",
      "Weighted Precision: 0.8522\n",
      "Weighted Recall: 0.8526\n",
      "Weighted F1 Score: 0.8506\n",
      "Weighted Average AUC: 0.8716\n",
      "\n",
      "Macro Averages (Unweighted):\n",
      "Macro Precision: 0.7809\n",
      "Macro Recall: 0.6779\n",
      "Macro F1 Score: 0.7066\n",
      "Average AUC (macro): 0.8133\n"
     ]
    }
   ],
   "source": [
    "return_scores(all_y2_pred, all_y2_true, y2, title=\"XGBoost on fp+descriptors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balanced Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Convert features list to a numpy array for modeling\n",
    "X3 = np.array(data['fingerprints'].tolist())\n",
    "y3 = data['Canonicalized Taste'].values\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder and transform the labels to integers\n",
    "y3_encoded = encoder.fit_transform(y3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py310_env/lib/python3.10/site-packages/imblearn/ensemble/_forest.py:577: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/opt/anaconda3/envs/py310_env/lib/python3.10/site-packages/imblearn/ensemble/_forest.py:589: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/opt/anaconda3/envs/py310_env/lib/python3.10/site-packages/imblearn/ensemble/_forest.py:601: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/opt/anaconda3/envs/py310_env/lib/python3.10/site-packages/imblearn/ensemble/_forest.py:577: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/opt/anaconda3/envs/py310_env/lib/python3.10/site-packages/imblearn/ensemble/_forest.py:589: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/opt/anaconda3/envs/py310_env/lib/python3.10/site-packages/imblearn/ensemble/_forest.py:601: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/opt/anaconda3/envs/py310_env/lib/python3.10/site-packages/imblearn/ensemble/_forest.py:577: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/opt/anaconda3/envs/py310_env/lib/python3.10/site-packages/imblearn/ensemble/_forest.py:589: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/opt/anaconda3/envs/py310_env/lib/python3.10/site-packages/imblearn/ensemble/_forest.py:601: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/opt/anaconda3/envs/py310_env/lib/python3.10/site-packages/imblearn/ensemble/_forest.py:577: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/opt/anaconda3/envs/py310_env/lib/python3.10/site-packages/imblearn/ensemble/_forest.py:589: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/opt/anaconda3/envs/py310_env/lib/python3.10/site-packages/imblearn/ensemble/_forest.py:601: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/opt/anaconda3/envs/py310_env/lib/python3.10/site-packages/imblearn/ensemble/_forest.py:577: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/opt/anaconda3/envs/py310_env/lib/python3.10/site-packages/imblearn/ensemble/_forest.py:589: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "/opt/anaconda3/envs/py310_env/lib/python3.10/site-packages/imblearn/ensemble/_forest.py:601: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "#  Using Balanced Random Forest\n",
    "model = BalancedRandomForestClassifier(\n",
    "    n_estimators=150,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=15,\n",
    "    random_state=101\n",
    ")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=101, shuffle=True)\n",
    "\n",
    "# Lists to store predictions and true labels across all folds\n",
    "all_y3_pred = []\n",
    "all_y3_true = []\n",
    "\n",
    "# Perform K-fold cross-validation\n",
    "for train_index, val_index in skf.split(X3, y3_encoded):\n",
    "    X3_train, X3_val = X3[train_index], X3[val_index]\n",
    "    y3_train, y3_val = y3_encoded[train_index], y3_encoded[val_index]\n",
    "\n",
    "    # Fit the model on training data\n",
    "    model.fit(X3_train, y3_train)\n",
    "\n",
    "    # Predict probabilities for the test set\n",
    "    y3_pred_proba = model.predict_proba(X3_val)\n",
    "\n",
    "    # Predicted class: highest probability\n",
    "    y3_pred = np.argmax(y3_pred_proba, axis=1)\n",
    "\n",
    "    # Collect true labels and predictions for evaluation\n",
    "    all_y3_true.extend(y3_val)\n",
    "    all_y3_pred.extend(y3_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Random Forest on fp\n",
      "\n",
      "Per-Class Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      bitter     0.6845    0.4039    0.5081      1676\n",
      "        sour     0.5583    0.8766    0.6822      1605\n",
      "       sweet     0.9436    0.7785    0.8531      9542\n",
      "       umami     0.0567    0.7241    0.1051        58\n",
      "   undefined     0.5263    0.7121    0.6053      2150\n",
      "\n",
      "    accuracy                         0.7375     15031\n",
      "   macro avg     0.5539    0.6991    0.5507     15031\n",
      "weighted avg     0.8105    0.7375    0.7580     15031\n",
      "\n",
      "Overall Accuracy: 0.7375\n",
      "\n",
      "Weighted Averages:\n",
      "Weighted Precision: 0.8105\n",
      "Weighted Recall: 0.7375\n",
      "Weighted F1 Score: 0.7580\n",
      "Weighted Average AUC: 0.8296\n",
      "\n",
      "Macro Averages (Unweighted):\n",
      "Macro Precision: 0.5539\n",
      "Macro Recall: 0.6991\n",
      "Macro F1 Score: 0.5507\n",
      "Average AUC (macro): 0.8154\n"
     ]
    }
   ],
   "source": [
    "return_scores(all_y3_pred, all_y3_true, y3, title=\"Balanced Random Forest on fp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost on 2048 bit fingerprints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16:51:59] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:52:00] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:52:00] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:52:00] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:52:00] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "# Loading the curated dataset from a CSV file\n",
    "data = pd.read_csv('fart_curated.csv')\n",
    "\n",
    "# Get Morgan fingerprints from SMILES\n",
    "data['2048-fingerprints'] = data['Standardized SMILES'].apply(lambda x: smiles_to_fingerprints(x, n_bits=2048))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Convert features list to a numpy array for modeling\n",
    "X4 = np.array(data['2048-fingerprints'].tolist())\n",
    "y4 = data['Canonicalized Taste'].values\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder and transform the labels to integers\n",
    "y4_encoded = encoder.fit_transform(y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py310_env/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:52:14] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py310_env/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:52:30] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py310_env/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:52:43] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py310_env/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:52:58] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/envs/py310_env/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:53:13] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/context.cc:196: XGBoost is not compiled with CUDA support.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Define the XGBClassifier model, same parameters as for the other RF models\n",
    "model = XGBClassifier(\n",
    "    n_estimators=150,\n",
    "    max_depth=15,\n",
    "    learning_rate=0.01,\n",
    "    subsample=0.8,               # now with full subsampling rate\n",
    "    objective='multi:softprob',\n",
    "    num_class=5,\n",
    "    eval_metric='mlogloss',\n",
    "    device='gpu',  # Ensure GPU is used for tree construction\n",
    "    random_state=101\n",
    ")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=101, shuffle=True)\n",
    "\n",
    "# Lists to store predictions and true labels across all folds\n",
    "all_y4_pred = []\n",
    "all_y4_true = []\n",
    "\n",
    "# Perform K-fold cross-validation\n",
    "for train_index, val_index in skf.split(X4, y4_encoded):\n",
    "    X4_train, X4_val = X4[train_index], X4[val_index]\n",
    "    y4_train, y4_val = y4_encoded[train_index], y4_encoded[val_index]\n",
    "\n",
    "    # Fit the model on training data\n",
    "    model.fit(X4_train, y4_train)\n",
    "\n",
    "    # Predict probabilities for the test set\n",
    "    y4_pred_proba = model.predict_proba(X4_val)\n",
    "\n",
    "    # Predicted class: highest probability\n",
    "    y4_pred = np.argmax(y4_pred_proba, axis=1)\n",
    "\n",
    "    # Collect true labels and predictions for evaluation\n",
    "    all_y4_true.extend(y4_val)\n",
    "    all_y4_pred.extend(y4_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost on Fingerprints\n",
      "\n",
      "Per-Class Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      bitter     0.8122    0.5805    0.6771      1676\n",
      "        sour     0.8288    0.8991    0.8625      1605\n",
      "       sweet     0.9274    0.9248    0.9261      9542\n",
      "       umami     0.7200    0.3103    0.4337        58\n",
      "   undefined     0.6277    0.7451    0.6814      2150\n",
      "\n",
      "    accuracy                         0.8556     15031\n",
      "   macro avg     0.7832    0.6920    0.7162     15031\n",
      "weighted avg     0.8604    0.8556    0.8546     15031\n",
      "\n",
      "Overall Accuracy: 0.8556\n",
      "\n",
      "Weighted Averages:\n",
      "Weighted Precision: 0.8604\n",
      "Weighted Recall: 0.8556\n",
      "Weighted F1 Score: 0.8546\n",
      "Weighted Average AUC: 0.8804\n",
      "\n",
      "Macro Averages (Unweighted):\n",
      "Macro Precision: 0.7832\n",
      "Macro Recall: 0.6920\n",
      "Macro F1 Score: 0.7162\n",
      "Average AUC (macro): 0.8221\n"
     ]
    }
   ],
   "source": [
    "return_scores(all_y4_pred, all_y4_true, y4, title=\"XGBoost on Fingerprints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
